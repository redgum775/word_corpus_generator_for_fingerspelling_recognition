{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プログレスバー\n",
    "class ProgressBar:\n",
    "  def __init__(self, max_id):\n",
    "    self.call = 0\n",
    "    self.max_id = max_id\n",
    "  \n",
    "  def show(self, id, comment=''):\n",
    "    if self.call == 0:\n",
    "      self.call = 1\n",
    "      print(f'{int(id/self.max_id*100): >3}%|{\"■\"*int((id/self.max_id)*20)+\"_\"*(20 - int((id/self.max_id)*20))}| {id}/{self.max_id}:{comment:128}', end=\"\")\n",
    "    elif id >= self.max_id:\n",
    "      print(f'\\r{int(id/self.max_id*100): >3}%|{\"■\"*int((id/self.max_id)*20)+\"_\"*(20 - int((id/self.max_id)*20))}| {id}/{self.max_id}:{comment:128}')\n",
    "    else:\n",
    "      print(f'\\r{int(id/self.max_id*100): >3}%|{\"■\"*int((id/self.max_id)*20)+\"_\"*(20 - int((id/self.max_id)*20))}| {id}/{self.max_id}:{comment:128}', end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規表現[あ-んー]をLと定めた時、Lの二つ組LLのリストを作成\n",
    "KANA = ['あ', 'い', 'う', 'え', 'お',\n",
    "        'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご',\n",
    "        'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ',\n",
    "        'た', 'だ', 'ち', 'ぢ', 'っ', 'つ', 'づ', 'て', 'で', 'と', 'ど',\n",
    "        'な', 'に', 'ぬ', 'ね', 'の',\n",
    "        'は', 'ば', 'ぱ', 'ひ', 'び', 'ぴ', 'ふ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ',\n",
    "        'ま', 'み', 'む', 'め', 'も',\n",
    "        'ゃ', 'や', 'ゅ', 'ゆ', 'ょ', 'よ',\n",
    "        'ら', 'り', 'る', 'れ', 'ろ',\n",
    "        'わ', 'を', 'ん', 'ー']\n",
    "LL_LIST = []\n",
    "for first in KANA:\n",
    "  for second in KANA:\n",
    "    LL_LIST.append(f'{first}{second}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語とLLのリストを読み込む\n",
    "dtype_dict = dict(zip(['単語']+LL_LIST, ['object']+['bool']*len(LL_LIST)))  # 読み取るときの型定義\n",
    "corpus_df = pd.read_csv('../output/words.csv', dtype=dtype_dict, encoding='utf-8')\n",
    "corpus_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_filter = LL_LIST.copy()\n",
    "corpus_for_fingerspelling = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プログレスバーを初期化\n",
    "progress_bar = ProgressBar(len(LL_LIST))\n",
    "\n",
    "# 単語の最大出力数\n",
    "MAX_WORDS = 1000\n",
    "\n",
    "while True:\n",
    "  if corpus_df[ll_filter].sum(axis=1).max() == 0:\n",
    "    # 新規LLが無くなったら処理を終了\n",
    "    print(f'No new LL combinations.')\n",
    "    break\n",
    "  \n",
    "  if MAX_WORDS == len(corpus_for_fingerspelling):\n",
    "    print(f'{MAX_WORDS} word.')\n",
    "    break\n",
    "  \n",
    "  # 一度しか出現しないLLを含む単語リストを作成\n",
    "  one_list = list(corpus_df[ll_filter].sum()[corpus_df[ll_filter].sum()[:]==1].index)\n",
    "\n",
    "  if not one_list:\n",
    "    # ②の処理\n",
    "    # LLのエンドロピーが最大化する単語を探す処理\n",
    "    # 新規LLの最大個数\n",
    "    max_count = corpus_df[ll_filter].sum(axis=1).max()\n",
    "    # 新規LLが最大個数のindexを取得\n",
    "    candidate_words_idx = list(corpus_df[ll_filter].sum(axis=1)[corpus_df[ll_filter].sum(axis=1)==max_count].index)\n",
    "\n",
    "    result = ''\n",
    "    maximum_entropy = -100\n",
    "    for word_idx in candidate_words_idx:\n",
    "      word = corpus_df.loc[word_idx]['単語']\n",
    "      entropy = 0\n",
    "      # エンドロピーを計算\n",
    "      for idx in range(len(word)-1):\n",
    "        # 既出のLLは計算に入れない\n",
    "        if word[idx: idx+2] not in ll_filter:\n",
    "          continue\n",
    "        pn = corpus_df[word[idx: idx+2]].sum() / len(corpus_df)\n",
    "        entropy += pn * math.log2(pn)\n",
    "      if maximum_entropy < -entropy:\n",
    "        maximum_entropy = -entropy\n",
    "        result = word\n",
    "    \n",
    "    for idx in range(len(result)-1):\n",
    "      if result[idx:idx+2] in ll_filter:\n",
    "        corpus_df = corpus_df.drop(result[idx:idx+2], axis='columns')\n",
    "        ll_filter.remove(result[idx:idx+2])\n",
    "\n",
    "    corpus_df = corpus_df.drop(corpus_df.index[corpus_df['単語']==result])\n",
    "    corpus_for_fingerspelling.append(result)\n",
    "    progress_bar.show(len(LL_LIST) - len(ll_filter), f'{result}')\n",
    "    continue\n",
    "\n",
    "  # ①の処理\n",
    "  # 一度しか出現しないLLがあるときの処理\n",
    "  for key in one_list:\n",
    "    word = corpus_df[corpus_df[key]==1]['単語']\n",
    "    if word.empty:\n",
    "      continue\n",
    "    word = word.iloc[-1]\n",
    "    \n",
    "    for idx in range(len(word)-1):\n",
    "      if word[idx:idx+2] in ll_filter:\n",
    "        corpus_df = corpus_df.drop(word[idx:idx+2], axis='columns')\n",
    "        ll_filter.remove(word[idx:idx+2])\n",
    "      if word[idx:idx+2] in one_list:\n",
    "        one_list.remove(word[idx:idx+2])\n",
    "    \n",
    "    corpus_df = corpus_df.drop(corpus_df.index[corpus_df['単語']==word])\n",
    "    corpus_for_fingerspelling.append(word)\n",
    "\n",
    "    progress_bar.show(len(LL_LIST) - len(ll_filter), f'{word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of LL Covers: {len(LL_LIST) - len(ll_filter)}')\n",
    "print(f'Coverage of LL: {((len(LL_LIST) - len(ll_filter)) / len(LL_LIST)) * 100 :.1f}%')\n",
    "print(f'Number of words: {len(corpus_for_fingerspelling)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_for_fingerspelling_file = '../output/corpus_for_fingerspelling_1000.txt'\n",
    "corpus_for_fingerspelling = sorted(corpus_for_fingerspelling)\n",
    "f = open(corpus_for_fingerspelling_file, 'w', encoding='utf-8')\n",
    "for word in corpus_for_fingerspelling:\n",
    "  f.write(f'{word}\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf013d35b017588c7d7e71f9a994c2c562f09e2e9412870a8ef22129528f5b72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
